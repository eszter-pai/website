<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Fine-Tuning LLM for Higher-Order Code Generation in COCOBOTS">
    <title>COCOBOTS Fine-Tuning - Eszter's Portfolio</title>
    <link rel="stylesheet" href="css/base.css">
    <link rel="stylesheet" href="css/layout.css">
    <link rel="stylesheet" href="css/utils/decorative.css">
    <link rel="stylesheet" href="css/utils/responsive.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Playfair+Display:wght@700;800&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
        }

        .blog-post {
            max-width: 900px;
            margin: 0 auto;
            padding: 80px 20px 60px;
            background: rgba(0, 0, 0, 0.4);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            color: #f4a8b8;
            text-decoration: none;
            font-size: 0.95rem;
            margin-bottom: 30px;
            transition: transform 0.2s ease;
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
        }

        .back-link:hover {
            transform: translateX(-5px);
        }

        .post-header {
            margin-bottom: 40px;
        }

        .post-title {
            font-size: 2.5rem;
            color: white;
            margin-bottom: 15px;
            line-height: 1.2;
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-weight: 700;
        }

        .post-meta {
            color: white;
            font-size: 0.95rem;
        }

        .post-image {
            width: 100%;
            border-radius: 12px;
            margin: 30px 0;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }

        .post-content {
            font-size: 1.1rem;
            line-height: 1.8;
            color: white;
        }

        .post-content h2 {
            font-size: 1.8rem;
            color: white;
            margin: 40px 0 20px;
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-weight: 700;
        }

        .post-content h3 {
            font-size: 1.4rem;
            color: white;
            margin: 30px 0 15px;
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-weight: 700;
        }

        .post-content p {
            margin-bottom: 20px;
        }

        .post-content ul, .post-content ol {
            margin: 20px 0;
            padding-left: 30px;
        }

        .post-content li {
            margin-bottom: 10px;
        }

        .highlight {
            background: linear-gradient(120deg, rgba(244, 168, 184, 0.3) 0%, rgba(244, 168, 184, 0.1) 100%);
            padding: 2px 6px;
            border-radius: 3px;
        }

        .tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin: 20px 0;
        }

        .tech-tag {
            background: rgba(244, 168, 184, 0.2);
            color: white;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 500;
        }

        .code-example {
            background: rgba(0, 0, 0, 0.3);
            border-left: 4px solid #f4a8b8;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
        }

        .code-example h4 {
            color: #f4a8b8;
            margin-bottom: 10px;
            font-size: 1rem;
        }

        .code-example pre {
            margin: 0;
            color: white;
            font-size: 0.95rem;
            line-height: 1.6;
        }

        @media (max-width: 768px) {
            .post-title {
                font-size: 2rem;
            }

            .post-content {
                font-size: 1rem;
            }
        }

        /* Results Table Styles */
        .results-table-wrapper {
            overflow-x: auto;
            margin: 30px 0;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }

        .results-table {
            width: 100%;
            border-collapse: collapse;
            background: white;
            font-size: 0.9rem;
            font-family: 'Inter', sans-serif;
        }

        .results-table thead tr:first-child {
            background: linear-gradient(135deg, #f4a8b8 0%, #f4b8c5 100%);
        }

        .results-table thead tr:nth-child(2) {
            background: linear-gradient(135deg, #f4a8b8 0%, #f4b8c5 100%);
        }

        .results-table thead tr:nth-child(3) {
            background: rgba(244, 168, 184, 0.3);
        }

        .results-table th {
            padding: 16px;
            color: white;
            font-weight: 600;
        }

        .results-table thead tr:nth-child(3) th {
            padding: 10px;
            color: #2c3e50;
            font-weight: 500;
            font-size: 0.85rem;
        }

        .results-table th.left-align {
            text-align: left;
        }

        .results-table th.center-align {
            text-align: center;
        }

        .results-table th.subheader-padding {
            padding: 12px;
            font-weight: 500;
        }

        .results-table th.border-right {
            border-right: 1px solid rgba(255, 255, 255, 0.3);
        }

        .results-table th.border-right-light {
            border-right: 1px solid rgba(255, 255, 255, 0.2);
        }

        .results-table th.border-right-pink {
            border-right: 1px solid rgba(244, 168, 184, 0.3);
        }

        .results-table th.border-right-pink-light {
            border-right: 1px solid rgba(244, 168, 184, 0.2);
        }

        .results-table th.bg-highlight {
            background: rgba(255, 255, 255, 0.1);
        }

        .results-table tbody tr {
            border-bottom: 1px solid #f0f0f0;
            transition: background-color 0.2s ease;
        }

        .results-table tbody tr:hover {
            background-color: rgba(244, 168, 184, 0.05);
        }

        .results-table td {
            padding: 14px;
            text-align: center;
            color: #2c3e50;
        }

        .results-table td.model-name {
            text-align: left;
            font-weight: 600;
        }

        .results-table td.score-perfect {
            color: #0066cc;
            font-weight: 700;
        }

        .results-table td.score-high {
            font-weight: 700;
        }

        .results-table td.bg-highlight-pink {
            background: rgba(244, 168, 184, 0.1);
        }

        .evaluation-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .evaluation-card {
            background: rgba(244, 168, 184, 0.1);
            padding: 25px;
            border-radius: 12px;
            border-left: 4px solid #f4a8b8;
        }

        .evaluation-card h3 {
            color: #f4a8b8;
            margin-top: 0;
            font-size: 1.3rem;
        }

        .evaluation-card ul {
            margin: 0;
            padding-left: 20px;
            line-height: 2;
        }

        .evaluation-card p {
            margin: 8px 0;
            line-height: 1.6;
        }

        .evaluation-card strong {
            color: #f4a8b8;
        }
    </style>
</head>
<body>
    <div class="decorative-dots top-right"></div>

    <article class="blog-post">
        <a href="index.html" class="back-link">
            <i class="fas fa-arrow-left"></i>
            Back to Portfolio
        </a>

        <header class="post-header">
            <h1 class="post-title">Fine-Tuning LLM for Higher-Order Code Generation</h1>
            <p class="post-meta">
                <time datetime="2024-10-15">October 2024</time>
            </p>
        </header>

        <div class="post-content">
            <img src="img/cocobot_finetune.PNG" alt="COCOBOTS Fine-Tuning Project" class="post-image">
            
            <h2>Overview</h2>
            <p>
                This project explores the challenges of teaching Large Language Models to generate <span class="highlight">higher-order code</span> 
                rather than simple first-order instructions. Developed as part of a university module at Universit√§t Potsdam, 
                the work investigates common LLM code generation issues through the lens of the COCOBOTS domain. A code generation 
                task where models must instruct bots to place objects on game boards.
            </p>

            <h2>Motivation</h2>
            <p>
                Current LLMs face significant limitations when generating functions in the COCOBOTS domain. The need for accurate 
                function generation is critical as it directly impacts developer productivity and code quality. Improved accuracy 
                in function generation can:
            </p>
            <ul>
                <li>Aid developers by automating repetitive coding tasks</li>
                <li>Reduce errors through consistent pattern recognition and abstraction</li>
                <li>Enhance overall productivity by generating maintainable, reusable code</li>
            </ul>

            <h2>The Problem: First-Order vs. Higher-Order Code</h2>
            <p>
                Many LLMs struggle with abstract code generation. When given instructions like "Stack a nut and washer in the 5th row 
                and 3rd column using red for the nut and yellow for the washer," models often generate verbose, repetitive first-order code:
            </p>

            <div class="code-example">
                <h4>First-Order Code:</h4>
                <pre>put(board, "nut", "red", 4, 3)
put(board, "washer", "yellow", 4, 3)</pre>
            </div>

            <p>
                While functional, this approach doesn't demonstrate true code abstraction. The ideal solution should use higher-order 
                functions that encapsulate the logic and make the code more maintainable and reusable:
            </p>

            <div class="code-example">
                <h4>Higher-Order Code:</h4>
                <pre>def m5(board, colors, x, y):
    shapes = ["nut", "washer"]
    for shape, color in zip(shapes, colors):
        put(board, shape, color, x, y)

m5(board, ["red", "yellow"], 4, 2)</pre>
            </div>

            <h2>Evaluation Overview</h2>
            <p>
                To assess the effectiveness of fine-tuning for higher-order code generation, we conducted comprehensive 
                evaluations across multiple models, datasets, and metrics:
            </p>

            <div class="evaluation-grid">
                <div class="evaluation-card">
                    <h3>Dataset</h3>
                    <div style="margin-bottom: 20px;">
                        <strong>First-Order</strong>
                        <p>Train (4144)<br>Validation (500)<br>Test (500)</p>
                    </div>
                    <div>
                        <strong>Higher-Order</strong>
                        <p>Train (1072)<br>Validation (130)<br>Test (130)</p>
                    </div>
                </div>

                <div class="evaluation-card">
                    <h3>Metrics</h3>
                    <ul>
                        <li><strong>Exact Match (EM)</strong></li>
                        <li><strong>CodeBLEU</strong></li>
                        <li><strong>Execution Success (ES)</strong></li>
                    </ul>
                </div>
            </div>

            <h2>Technology Stack</h2>
            <div class="tech-stack">
                <span class="tech-tag">Python</span>
                <span class="tech-tag">PyTorch</span>
                <span class="tech-tag">Transformers</span>
                <span class="tech-tag">LoRA</span>
                <span class="tech-tag">PEFT</span>
                <span class="tech-tag">Code Generation</span>
                <span class="tech-tag">NLP Research</span>
                <span class="tech-tag">Model Fine-Tuning</span>
            </div>

            <h2>Fine-Tuning Approach</h2>
            <p>
                Using <span class="highlight">LoRA (Low-Rank Adaptation)</span> with <span class="highlight">Unsloth</span>, 
                we efficiently fine-tuned language models on curated COCOBOTS code examples. This approach significantly reduces 
                computational costs while teaching models to recognize patterns and generate reusable function definitions.
            </p>

            <h2>Results - First-Order Training, Inference on Both</h2>

            <div class="results-table-wrapper">
                <table class="results-table">
                    <thead>
                        <tr>
                            <th rowspan="2" class="left-align border-right">Models</th>
                            <th colspan="4" class="center-align border-right">Exact Match</th>
                            <th colspan="4" class="center-align border-right">CodeBLEU</th>
                            <th colspan="4" class="center-align">Execution Success</th>
                        </tr>
                        <tr>
                            <th colspan="2" class="center-align subheader-padding border-right-light bg-highlight">Pretrained</th>
                            <th colspan="2" class="center-align subheader-padding border-right">Fine-Tuned</th>
                            <th colspan="2" class="center-align subheader-padding border-right-light bg-highlight">Pretrained</th>
                            <th colspan="2" class="center-align subheader-padding border-right">Fine-Tuned</th>
                            <th colspan="2" class="center-align subheader-padding border-right-light bg-highlight">Pretrained</th>
                            <th colspan="2" class="center-align subheader-padding">Fine-Tuned</th>
                        </tr>
                        <tr>
                            <th class="border-right-pink"></th>
                            <th>First-Order</th>
                            <th class="border-right-pink-light">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink-light">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink-light">Higher-Order</th>
                            <th>First-Order</th>
                            <th>Higher-Order</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="model-name">CodeLlama-7b-Instruct</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>47.20%</td>
                            <td>0.00%</td>
                            <td>29.04%</td>
                            <td>12.77%</td>
                            <td>78.96%</td>
                            <td>16.44%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-high bg-highlight-pink">91.40%</td>
                            <td>14.60%</td>
                        </tr>
                        <tr>
                            <td class="model-name">CodeLlama-13b-Instruct</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>9.80%</td>
                            <td>0.00%</td>
                            <td>27.08%</td>
                            <td>13.54%</td>
                            <td>69.81%</td>
                            <td>16.22%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-high bg-highlight-pink">84.80%</td>
                            <td>11.50%</td>
                        </tr>
                        <tr>
                            <td class="model-name">Llama-3.1-8B</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>54.00%</td>
                            <td>0.00%</td>
                            <td>25.10%</td>
                            <td>12.59%</td>
                            <td>80.89%</td>
                            <td>13.42%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-high bg-highlight-pink">100%</td>
                            <td>76.92%</td>
                        </tr>
                        <tr>
                            <td class="model-name">Llama-3.2-3B</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>44.40%</td>
                            <td>0.00%</td>
                            <td>25.48%</td>
                            <td>12.81%</td>
                            <td>76.97%</td>
                            <td>29.08%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-high bg-highlight-pink">81%</td>
                            <td>4.60%</td>
                        </tr>
                        <tr>
                            <td class="model-name">Mistral-7B-v0.1</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect">100.00%</td>
                            <td>0.00%</td>
                            <td>25.44%</td>
                            <td>12.86%</td>
                            <td class="score-perfect">100.00%</td>
                            <td>10.68%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect bg-highlight-pink">100%</td>
                            <td>65.38%</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h2>Key Findings</h2>
            <ul>
                <li>Mistral-7B achieved perfect 100% scores across all first-order metrics after fine-tuning</li>
                <li>All models showed 0% Exact Match on higher-order tasks, indicating no cross-order generalization</li>
                <li>Execution Success rates (81-100%) were significantly higher than Exact Match scores, suggesting functionally correct but syntactically different outputs</li>
            </ul>

            <h2>Results - Higher-Order Training, Inference on Both</h2>

            <div class="results-table-wrapper">
                <table class="results-table">
                    <thead>
                        <tr>
                            <th rowspan="2" class="left-align border-right">Models</th>
                            <th colspan="4" class="center-align border-right">Exact Match</th>
                            <th colspan="4" class="center-align border-right">CodeBLEU</th>
                            <th colspan="4" class="center-align">Execution Success</th>
                        </tr>
                        <tr>
                            <th colspan="2" class="center-align subheader-padding border-right-light bg-highlight">Pretrained</th>
                            <th colspan="2" class="center-align subheader-padding border-right">Fine-Tuned</th>
                            <th colspan="2" class="center-align subheader-padding border-right-light bg-highlight">Pretrained</th>
                            <th colspan="2" class="center-align subheader-padding border-right">Fine-Tuned</th>
                            <th colspan="2" class="center-align subheader-padding border-right-light bg-highlight">Pretrained</th>
                            <th colspan="2" class="center-align subheader-padding">Fine-Tuned</th>
                        </tr>
                        <tr>
                            <th class="border-right-pink"></th>
                            <th>First-Order</th>
                            <th class="border-right-pink-light">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink-light">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink-light">Higher-Order</th>
                            <th>First-Order</th>
                            <th>Higher-Order</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="model-name">CodeLlama-7b-Instruct</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>2.60%</td>
                            <td>7.69%</td>
                            <td>29.04%</td>
                            <td>12.77%</td>
                            <td>47.27%</td>
                            <td class="score-high bg-highlight-pink">72.76%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>14.60%</td>
                            <td>41.50%</td>
                        </tr>
                        <tr>
                            <td class="model-name">CodeLlama-13b-Instruct</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>27.08%</td>
                            <td>13.54%</td>
                            <td class="score-high">67.25%</td>
                            <td>23.09%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect bg-highlight-pink">89.20%</td>
                            <td>11.50%</td>
                        </tr>
                        <tr>
                            <td class="model-name">Llama-3.1-8B</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>26.15%</td>
                            <td>25.10%</td>
                            <td>12.59%</td>
                            <td>52.76%</td>
                            <td class="score-high bg-highlight-pink">81.66%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>14.80%</td>
                            <td class="score-perfect">83.80%</td>
                        </tr>
                        <tr>
                            <td class="model-name">Llama-3.2-3B</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>13.00%</td>
                            <td>11.54%</td>
                            <td>25.48%</td>
                            <td>12.81%</td>
                            <td>57.83%</td>
                            <td class="score-high">60.93%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>24%</td>
                            <td>23.80%</td>
                        </tr>
                        <tr>
                            <td class="model-name">Mistral-7B-v0.1</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>25.44%</td>
                            <td>12.86%</td>
                            <td>36.90%</td>
                            <td>58.33%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>0%</td>
                            <td class="score-high">65.38%</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h2>Key Findings</h2>
            <ul>
                <li>Llama-3.1-8B achieved 26.15% Exact Match and 83.80% Execution Success on higher-order tasks, the best higher-order performance</li>
                <li>CodeBLEU scores for higher-order tasks reached 72.76-81.66%, indicating good structural similarity despite lower exact matches</li>
                <li>Most models struggled with first-order Exact Match (0-13%), but maintained reasonable Execution Success, showing bidirectional capability</li>
            </ul>

            <h2>Results - Both Training, Inference on Both</h2>

            <div class="results-table-wrapper">
                <table class="results-table">
                    <thead>
                        <tr>
                            <th rowspan="2" class="left-align border-right">Models</th>
                            <th colspan="4" class="center-align border-right">Exact Match</th>
                            <th colspan="4" class="center-align border-right">CodeBLEU</th>
                            <th colspan="4" class="center-align">Exec Success</th>
                        </tr>
                        <tr>
                            <th colspan="2" class="center-align subheader-padding border-right-light bg-highlight">Pretrained</th>
                            <th colspan="2" class="center-align subheader-padding border-right">Fine-Tuned</th>
                            <th colspan="2" class="center-align subheader-padding border-right-light bg-highlight">Pretrained</th>
                            <th colspan="2" class="center-align subheader-padding border-right">Fine-Tuned</th>
                            <th colspan="2" class="center-align subheader-padding border-right-light bg-highlight">Pretrained</th>
                            <th colspan="2" class="center-align subheader-padding">Fine-Tuned</th>
                        </tr>
                        <tr>
                            <th class="border-right-pink"></th>
                            <th>First-Order</th>
                            <th class="border-right-pink-light">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink-light">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink">Higher-Order</th>
                            <th>First-Order</th>
                            <th class="border-right-pink-light">Higher-Order</th>
                            <th>First-Order</th>
                            <th>Higher-Order</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="model-name">CodeLlama-7b-Instruct</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect">95.40%</td>
                            <td>44.62%</td>
                            <td>29.04%</td>
                            <td>12.77%</td>
                            <td class="score-perfect">98.36%</td>
                            <td class="score-perfect bg-highlight-pink">90.57%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect bg-highlight-pink">95.40%</td>
                            <td>54.60%</td>
                        </tr>
                        <tr>
                            <td class="model-name">CodeLlama-13b-Instruct</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect">92.40%</td>
                            <td>6.92%</td>
                            <td>27.08%</td>
                            <td>13.54%</td>
                            <td class="score-perfect">98.74%</td>
                            <td>34.41%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect bg-highlight-pink">92.40%</td>
                            <td class="score-high">69.20%</td>
                        </tr>
                        <tr>
                            <td class="model-name">Llama-3.1-8B</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>54.00%</td>
                            <td>3.08%</td>
                            <td>25.10%</td>
                            <td>12.59%</td>
                            <td>80.89%</td>
                            <td>36.52%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect bg-highlight-pink">100%</td>
                            <td>22.30%</td>
                        </tr>
                        <tr>
                            <td class="model-name">Llama-3.2-3B</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td>54.00%</td>
                            <td>19.23%</td>
                            <td>25.48%</td>
                            <td>12.81%</td>
                            <td>80.89%</td>
                            <td class="score-high">81.68%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect bg-highlight-pink">100%</td>
                            <td>53%</td>
                        </tr>
                        <tr>
                            <td class="model-name">Mistral-7B-v0.1</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect">100.00%</td>
                            <td>4.62%</td>
                            <td>25.44%</td>
                            <td>12.86%</td>
                            <td class="score-perfect">100.00%</td>
                            <td class="score-high">74.25%</td>
                            <td>0.00%</td>
                            <td>0.00%</td>
                            <td class="score-perfect bg-highlight-pink">100%</td>
                            <td>27.69%</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h2>Key Findings</h2>
            <ul>
                <li>Combined training achieved the best balance: 92-100% first-order Exact Match and up to 44.62% higher-order Exact Match</li>
                <li>CodeLlama-7b showed exceptional CodeBLEU scores (98.36% first-order, 90.57% higher-order), indicating superior code structure quality</li>
                <li>Three models reached 100% Execution Success on first-order tasks, demonstrating highly reliable code generation</li>
            </ul>

            <h2>Error Analysis</h2>
            <p>
                Beyond overall performance metrics, we analyzed the types of errors generated by the models to understand 
                their failure modes and identify areas for improvement:
            </p>

            <img src="img/Error count per model.PNG" alt="Error Analysis - Error Counts per Model" class="post-image">

            <h2>Conclusion</h2>
            <p>
                The comprehensive evaluation across different training strategies revealed several key insights:
            </p>
            <ul>
                <li><strong>First-Order Code Inference:</strong> Models achieved high execution success rates (~80-100%) for first-order code generation, irrespective of the training data used. This demonstrates that all training approaches effectively teach models to generate functional first-order code</li>
                <li><strong>Higher-Order Code Inference:</strong> Performance varied significantly based on training strategy. Models trained only on higher-order data achieved the highest higher-order execution success (83%), while performance decreased with first-order-only training (76%) and combined data training (69%). This suggests a trade-off between specialization and versatility</li>
                <li><strong>Common Error Patterns:</strong> Syntax Errors (particularly unclosed parentheses) and Placement Errors emerged as the most frequent error types across all models. The Mistral-7B model exhibited notably high placement errors, while CodeLlama models showed more balanced error distributions</li>
            </ul>
        </div>
    </article>

    <svg class="decorative-wave" viewBox="0 0 1200 200" preserveAspectRatio="none" style="margin-top: 60px;">
        <path d="M 0 0 C 60 0 120 180 280 190 C 400 195 550 110 700 100 C 850 90 1000 130 1200 160 L 1200 200 L 0 200 Z" 
              fill="rgba(244, 168, 184, 0.15)"/>
        <path d="M 0 20 C 60 20 120 200 280 200 C 400 200 550 130 700 120 C 850 110 1000 150 1200 180 L 1200 200 L 0 200 Z" 
              fill="rgba(244, 168, 184, 0.08)" opacity="0.6"/>
    </svg>

    <script>
        // Smooth page transition for back to portfolio link
        document.addEventListener('DOMContentLoaded', function() {
            const backLink = document.querySelector('.back-link');
            
            if (backLink) {
                backLink.addEventListener('click', function(e) {
                    const href = this.getAttribute('href');
                    
                    // Only apply transition for internal HTML pages
                    if (href && href.endsWith('.html')) {
                        e.preventDefault();
                        
                        // Add fade-out class
                        document.body.classList.add('page-transition');
                        
                        // Navigate after transition
                        setTimeout(() => {
                            window.location.href = href;
                        }, 400);
                    }
                });
            }
        });
    </script>
</body>
</html>
